{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "\r\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def get_image_list(dir):\r\n",
    "    return os.listdir(dir)\r\n",
    "\r\n",
    "def read_save_image(i_dir, s_dir):\r\n",
    "    read_image = cv2.imread(i_dir)\r\n",
    "    cv2.imwrite(s_dir, read_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 이미지 jpg로 변환\r\n",
    "data_folder_dir = 'Humans'\r\n",
    "save_data_folder_dir = 'jpg_Humans'\r\n",
    "\r\n",
    "image_list = get_image_list(data_folder_dir)\r\n",
    "\r\n",
    "for idx, image in tqdm(enumerate(image_list)):\r\n",
    "    i_dir = data_folder_dir + '/' + image\r\n",
    "    s_dir = save_data_folder_dir + '/' + str(idx) + '.jpg'\r\n",
    "\r\n",
    "    read_save_image(i_dir, s_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "72it [00:03, 20.53it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-378a9c203ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0ms_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_data_folder_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mread_save_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-a844f6f82942>\u001b[0m in \u001b[0;36mread_save_image\u001b[1;34m(i_dir, s_dir)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_save_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mread_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\r\n",
    "\r\n",
    "def face_detection_crop_resize(image, dsize):\r\n",
    "    # 인식된 얼굴 좌표 [x, y, w, h]\r\n",
    "    face_location = detector.detectMultiScale(image)\r\n",
    "\r\n",
    "    if len(face_location) < 1:\r\n",
    "        return image, False\r\n",
    "    else:\r\n",
    "        x = face_location[0][0]\r\n",
    "        y = face_location[0][1]\r\n",
    "        w = face_location[0][2]\r\n",
    "        h = face_location[0][3]\r\n",
    "\r\n",
    "        cropped_image = image[y: y + h, x: x + w]\r\n",
    "        resized_image = cv2.resize(cropped_image, dsize=dsize)\r\n",
    "\r\n",
    "        return resized_image, True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "data_folder_dir = 'jpg_Humans'\r\n",
    "save_data_folder_dir = 'Cropped_Images'\r\n",
    "dsize = (256, 256)\r\n",
    "\r\n",
    "image_list = get_image_list(data_folder_dir)\r\n",
    "\r\n",
    "for idx, image in tqdm(enumerate(image_list)):\r\n",
    "    i_dir = data_folder_dir + '/' + image\r\n",
    "    s_dir = save_data_folder_dir + '/' + image\r\n",
    "\r\n",
    "    image = cv2.imread(i_dir)\r\n",
    "    resized_image, result = face_detection_crop_resize(image, dsize)\r\n",
    "    if result:\r\n",
    "        cv2.imwrite(s_dir, resized_image)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "7219it [24:44,  4.86it/s]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}